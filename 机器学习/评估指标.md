### 回归类评估指标

#### 1. 平均绝对值误差（MAE）

$$
MAE = \frac{1}{m}\sum_{i = 1}^{m}|h(x_i) - y_i|
$$

​	MAE难以求导，比较难计算

#### 2. 均方差误差（MSE）

$$
MSE = \frac{1}{m}\sum_{i = 1}^{m}(h(x_i) - y_i) ^ 2
$$



​	MSE放大了数据的本来单位，于是我们可以用下面的均方根误差来计算。

#### 3. 均方根误差（RMSE）

$$
RMSE = \frac{1}{m}\sqrt{\sum_{i = 1}^{m}(h(x_i) - y_i) ^ 2}
$$

​	很多时候，我们需要在不同的单位空间中评估拟合程度，比如上海房价和四五线城市房价，他们本来数量级不在一个维度上，如果用一个模型去评估，用均方根误差无法度量这两者的拟合程度。

#### 4. $R ^ 2$系数

$$
SST = \sum_{i = 1}^{m}(y_i - \overline {y}) ^ 2  \qquad \text{SST = sum of total square}
$$

$$
SSR = \sum_{i = 1}^{m}(h(x_i) - \overline{y})^2 \qquad \text{SSR = sum of due to regression}
$$

$$
SSE = \sum_{i = 1}^{m}(h(x_i) - y_i) ^ 2 \qquad \text{SSE = sum of due to error}
$$

$$
R^2 = \frac{SSR}{SST} \approx 1 - \frac{SSE}{SST} = 1 - \frac{MSE}{VAR}
$$

如果结果是0，则表示模型不能预测因变量。结果是1，则表示拟合很好。结果越大，表示拟合程度越好。



### 分类算法评估指标

#### 1. 精度(Accuracy)

精度是最简单的评估指标。它是用来预测正确样本占总样本的比例，取值范围[0,1]，取值越大，预测能力越强。
$$
Acc(y, y_i) = \frac{1}{n}\sum_{i=1}^{n}sign(y_i, y)
$$

其中
$$
sign(y_i, y) =   \begin{cases}
1 & y_i^` = y_i \\
0 & y_i^` \neq y_i\\
\end{cases}
$$

当样本中类别数量严格不均衡的时候，例如正样本999个，负样本5个，如果将所有样本预测为正样本，则精度为99%，但这是不符合意义的。

#### 2. 混淆矩阵(Confusion Matrix)

混淆矩阵是一种表示正负样本预测比例的图形表示。

|                    | Predict（Positive） | Predict（Negative） |
| :----------------: | :-----------------: | :-----------------: |
| Condition（True）  |         TP          |         FN          |
| Condition（False） |         FP          |         TN          |

##### 准确率(Precision)

Precision是分类器预测正样本中预测正确的样本比例，取值越大，预测能力越强。
$$
Pre = \frac{TP}{TP + FP}
$$

##### 查全率(Recall)

Recall是分类器识别出的正样本占所有正样本的比例，取值越大，识别出的正样本越多，预测能力越强。
$$
Recall = \frac{TP}{TP + FN}
$$
Precision和Recall一般是互相制约的，即一个指标越大，则另一个指标可能变小。

例如对于地震预测来说，我们就希望Recall尽量高点，而相对的Precision则可以低点。

###  

#### 3. $F_\beta$ Store

Precision和Recall互相影响，理想情况下要做到两者都很高。都是一般情况下是相互制约的。为了均衡这两个指标，我们一般使用Precision和Recall的加权调和平均来衡量，即$F_\beta$ Score，公式如下：
$$
F_\beta = (1 + \beta ^ 2)\frac{P*R}{\beta ^ 2 * P + R}
$$
$\beta$表示权重，当$\beta$越大时候，Recall的权重越大，当$\beta$越小的时候，Precision的权重越大。

由于$F_\beta$ Store无法直观观察数据情况，业务含义相对较弱，因此实际工作用到的不多。

#### 4. ROC和AUC

AUC是一种模型分类指标，且仅仅是二分类模型的评估指标。AUC是Area Under Curve的简称，其中Curve就是ROC（Receiver Operating Characteristic）。

##### ROC

ROC曲线由TPR和FPR组成，其中
$$
TPR = \frac{TP}{TP + FN}
$$

$$
FPR = \frac{FP}{FP + TN}
$$

TPR表示查全率（Recall）也叫真阳性率，FPR表示负样本中错误判断的比例，也叫假阳性率
$$
C_{ROC} = \frac{TPR}{FPR}
$$
即x轴为假阳性率（FPR），y轴位真阳性率（TPR）。

理想情况下，我们需要TPR尽量高，同时FPR尽量低。例如对于癌症检测，我们希望检出尽量多的病人，同时希望降低正常人预测成病人的比例。

一般来说，当TPR高时，FPR也会相应很高。极端情况下把所有的样本都看作正样本，此时TPR = FPR = 1。

例如，我们假设正常人和病人都满足正态分布，那么当我们选择合适的阈值时，混淆矩阵值如下图所示。

![True negative, false negative, true positive and false positive fractions change when changing the criterion value.](https://www.medcalc.org/manual/_help/images/roc_intro1.png)

当阈值从小到大变化时，我们就可以画出ROC曲线了，一般来说ROC曲线如下图所示：

![Example of ROC graph](https://www.medcalc.org/manual/_help/images/roc_intro3.png)

曲线距离左上角越近，那么表示分类器分类效果越好，也就是TPR/FPR值越大，越能满足我们的要求。为了评估ROC的分类效果，我们使用ROC曲线下方的面积，即AUC来表示量化分类效果。显然，面积越大，分类效果越好。

##### AUC

AUC表示正样本的预测结果大于负样本预测结果的概率。AUC值越大，表示正样本和负样本分的越开，即能够更简单的将正样本和负样本分开。

**AUC反应的是分类器对样本的排序能力**。

另外注意，AUC对样本类别是否均衡不敏感，这也是不均衡样本通常用AUC评估的一个原因。